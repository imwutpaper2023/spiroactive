{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#Installing the modAL library\n",
        "!pip install -qq modAL"
      ],
      "metadata": {
        "id": "uYkcthXHafW3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Importing necessary libraries \n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np \n",
        "import matplotlib.pyplot as plt \n",
        "%matplotlib inline\n",
        "\n",
        "import modAL \n",
        "from modAL.models import ActiveLearner, CommitteeRegressor\n",
        "from modAL.uncertainty import uncertainty_sampling\n",
        "from modAL.disagreement import max_std_sampling,KL_max_disagreement,max_disagreement_sampling\n",
        "\n",
        "# import catboost as cb\n",
        "from sklearn.model_selection import KFold, RandomizedSearchCV,GridSearchCV\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor,GradientBoostingRegressor\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.metrics import mean_absolute_percentage_error\n",
        "\n",
        "import seaborn as sns\n",
        "from scipy.stats import randint, uniform \n",
        "\n",
        "np.random.seed(42)\n",
        "import random\n",
        "random.seed(0)"
      ],
      "metadata": {
        "id": "jZ3RTxYyahEA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "from sklearn.exceptions import DataConversionWarning\n",
        "warnings.filterwarnings(action='ignore', category=DataConversionWarning)"
      ],
      "metadata": {
        "id": "pZJw3kyya7tP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from probml_utils import savefig,latexify"
      ],
      "metadata": {
        "id": "RoURKjy6cH9P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%env LATEXIFY=1\n",
        "%env FIG_DIR = figures"
      ],
      "metadata": {
        "id": "qf-jWVUUcEju"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "latexify(fig_width=3,fig_height=2)"
      ],
      "metadata": {
        "id": "6y7muGTmcGXQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X= np.load(\"FVC_FEATURES_60.npy\")\n",
        "Y= np.load(\"FVC_LABELS_60.npy\")"
      ],
      "metadata": {
        "id": "yJ3r_74dXHJv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X= np.delete(X,[23,55,4,9,52,44,45,33,43,20,1,50], axis=0)\n",
        "Y= np.delete(Y,[23,55,4,9,52,44,45,33,43,20,1,50], axis=0)"
      ],
      "metadata": {
        "id": "vvV4A8daXHIZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_idx= [30, 47, 15, 29, 35, 9, 24, 12] \n",
        "test_idx= [45, 39, 8, 4, 20, 32, 25, 46, 42, 41]\n",
        "query_idx = [i for i in range(0,48) if i not in train_idx+test_idx]"
      ],
      "metadata": {
        "id": "Jrxp5urpXHDh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mape(model, feat, train_label):\n",
        "  pred = model.predict(feat)\n",
        "  mpe = 100*np.mean(np.abs((train_label.reshape(-1) -pred)/train_label.reshape(-1)))\n",
        "  return mpe"
      ],
      "metadata": {
        "id": "WGpB9wVjXHCa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def loss_fnc(train_label,pred):\n",
        "    mape = 100*np.mean(np.abs((train_label.reshape(-1) -pred)/train_label.reshape(-1)))\n",
        "    return mape\n",
        "\n",
        "from sklearn.metrics import make_scorer\n",
        "loss = make_scorer(loss_fnc, greater_is_better=False)"
      ],
      "metadata": {
        "id": "a7Wz8JapXG9-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Starting RF\")\n",
        "param_grid = {\n",
        "    'bootstrap': [True, False],\n",
        "    'max_depth': randint(10,50),\n",
        "    'max_features': [2, 3, 4, 'sqrt','auto'],\n",
        "    'min_samples_leaf': randint(1,10),\n",
        "    'min_samples_split': randint(2,10),\n",
        "    'n_estimators': randint(10,150)\n",
        "}\n",
        "print(\"params_initialised\")\n",
        "rf = RandomForestRegressor(random_state=0,verbose=0)\n",
        "print(\"model_done\")\n",
        "grid_search_rf = RandomizedSearchCV(estimator = rf, param_distributions = param_grid, \n",
        "                          cv=2,n_jobs = -1, verbose = 0, scoring=loss, n_iter=20,random_state=100)\n",
        "print(\"grid_done\")\n",
        "    \n",
        "                   \n",
        "print(\"Initialising Indexes\")\n",
        "indexAdded = []\n",
        "recordedMPE = []\n",
        "best_param_dict = {}\n",
        "\n",
        "original_train = train_idx.copy()\n",
        "\n",
        "while len(query_idx):\n",
        "    print(\"Current length of Pool set is = {}\".format(len(query_idx)))\n",
        "\n",
        "    lowest_mpe = 100 #reset this for each run\n",
        "\n",
        "    for datapoint_idx in query_idx:\n",
        "        train_idx = original_train.copy()\n",
        "        train_idx.append(datapoint_idx)\n",
        "\n",
        "        X_train, X_test = np.float32(X[train_idx]), np.float32(X[test_idx])\n",
        "        Y_train, Y_test = np.float32(Y[train_idx]), np.float32(Y[test_idx])\n",
        "\n",
        "        grid_search_rf.fit(X_train, Y_train)\n",
        "        #grid_search.best_params_\n",
        "        best_grid = grid_search_rf.best_estimator_\n",
        "        grid_mpe = mape(best_grid, X_test, Y_test)\n",
        "\n",
        "        #lowest_mpe_datapoint = datapoint_idx\n",
        "\n",
        "        if(grid_mpe) < lowest_mpe:\n",
        "            idx_best_reduction = datapoint_idx;\n",
        "            final_grid = best_grid;\n",
        "            lowest_mpe = grid_mpe\n",
        "\n",
        "    indexAdded.append(idx_best_reduction)\n",
        "    recordedMPE.append(lowest_mpe)\n",
        "    best_param_dict[idx_best_reduction] = final_grid\n",
        "    print(\"Best Grid:\",final_grid)\n",
        "    print(\"Lowest MPE recorded = {}\\n\".format(lowest_mpe))\n",
        "\n",
        "    #remove the index from the query which was just detected to give the max differnece in MPE\n",
        "    query_idx.remove(indexAdded[len(indexAdded)-1]) \n",
        "    #add the index to the original train set which was just detected to give the max differnece in MPE\n",
        "    original_train.append(indexAdded[len(indexAdded)-1])"
      ],
      "metadata": {
        "id": "kiqL9tLBXG8_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Random Sampling"
      ],
      "metadata": {
        "id": "lOgS17YbbMKY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Splitting the data into Train and Pool set \n",
        "X_train,X_test, X_pool = X[train_idx],X[test_idx] ,X[query_idx] \n",
        "Y_train,Y_test, Y_pool = Y[train_idx],Y[test_idx] ,Y[query_idx]"
      ],
      "metadata": {
        "id": "YZbdCYnmXG5M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def GP_regression_std(regressor, X):\n",
        "    _, std = regressor.predict(X, return_std=True)\n",
        "    mean_std = sum(std)/(len(std))\n",
        "    #print(len(std))\n",
        "    query_idx = np.argmax(std)\n",
        "    return query_idx, X[query_idx],mean_std"
      ],
      "metadata": {
        "id": "RPh0KxjmXG4F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learner_list_a = [ActiveLearner(estimator=RandomForestRegressor(random_state=0),X_training=X_train, y_training=Y_train)\n",
        "               ]\n",
        "committee_a = CommitteeRegressor(learner_list=learner_list_a,query_strategy=GP_regression_std)\n",
        "pred, std = committee_a.predict(X[test_idx], return_std=True)\n",
        "initial_scores_0= mape(pred,Y_test)          "
      ],
      "metadata": {
        "id": "s1pyIaT6bQRg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Randomly sampling 100 points from the pool and adding them to the train set. We repeat this process 20 times with different subsets of data.\n",
        "random_scores=[] \n",
        "\n",
        "for i in range(20):\n",
        "    #Creating a copy of the Train Set\n",
        "    X_random_train=X_train \n",
        "    Y_random_train=Y_train\n",
        "    #Creating a copy of the Pool Set\n",
        "    X_random_pool = X_pool \n",
        "    Y_random_pool = Y_pool\n",
        "\n",
        "    scores=[initial_scores_0] \n",
        "\n",
        "    for idx in range(len(pool_idx)):\n",
        "      query_id = np.random.choice(range(X_random_pool.shape[0]), size=1, replace=False) #Querying a random index from the pool \n",
        "      X_random_train = np.concatenate((X_random_train, X_random_pool[query_id])) #Appending the Query point to the train set \n",
        "      Y_random_train = np.concatenate((Y_random_train, Y_random_pool[query_id]))\n",
        "      committee_a.fit(X_random_train,Y_random_train) #Training the committee with the updated train set\n",
        "      X_random_pool = np.delete(X_random_pool, query_id, axis=0) #Deleting the query point from the pool set\n",
        "      Y_random_pool = np.delete(Y_random_pool, query_id)\n",
        "      predn_, stdd_ = committee_a.predict(X_test, return_std=True)\n",
        "      scores.append(mape(predn_,Y_test)) #Calculating the score on the updated pool set\n",
        "     \n",
        "    random_scores.append(scores)"
      ],
      "metadata": {
        "id": "Z1DUpdl9bXQx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random_scores_array = np.array(random_scores) \n",
        "random_mean= np.array(np.mean(random_scores_array,axis=0))\n",
        "random_std = np.array(np.std(random_scores_array,axis=0))"
      ],
      "metadata": {
        "id": "xA_yMsAFbZ3d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "p = plt.rcParams\n",
        "p[\"axes.grid\"] = True\n",
        "p[\"grid.color\"] = \"#999999\"\n",
        "p[\"grid.linestyle\"] = \"--\"\n",
        "\n",
        "p[\"lines.marker\"] = \"o\"\n",
        "p[\"lines.markeredgecolor\"] = \"auto\"\n",
        "p[\"lines.markerfacecolor\"] = \"white\"\n",
        "p[\"lines.markersize\"] = 3\n",
        "\n",
        "x= [i for i in range(0,31)]\n",
        "plt.plot(x,random_mean,color='#4caf50', label=\"(RF,Random)\")\n",
        "plt.fill_between(x, random_mean - random_std, random_mean + random_std, color=\"#4caf50\",alpha=0.5, label=\"95\\% interval\")  \n",
        "plt.plot(recordedMPE,color=\"#ff7f50\", label = \"(RF,Oracle)\")\n",
        "plt.xlabel('Number of Points queried')\n",
        "plt.ylabel('MAPE')\n",
        "plt.legend()\n",
        "sns.despine()\n",
        "savefig(\"oracle_vs_random\")\n"
      ],
      "metadata": {
        "id": "POmMr_lIbfNU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}